import os
import glob
import pkg_resources
from justdeepit.utils import ImageAnnotation, ImageAnnotations
from justdeepit.models.utils.mmdetbase import MMDetBase

class IS:
    """A class to generate model for instance segmentation

    The :class:`IS <justdeepit.models.IS>` class is used for generating
    deep neural network (DNN) architectures (i.e., models) for instance segmentation
    by internally calling the MMDetection or Detectron2 library.

    User can specify DNN architectures using the ``model_arch`` or ``model_config``
    argument. If the ``model_arch`` is specified and ``model_config`` is ``None``,
    the :class:`IS <justdeepit.models.IS>` class generates a DNN architecture
    according the ``model_arch`` using the pre-defined configuration.
    The pre-defined DNN architectures for instance segmentation can be checked with the
    :func:`available_architectures <justdeepit.models.IS.available_architectures>` method.
    Alternatively, if the ``model_config`` argument is specified,
    the :class:`IS <justdeepit.models.IS>` class generates a DNN architecture
    following the configuration specified with the ``model_config``,
    regardless of whether the ``model_arch`` is specified.


    Args:
        class_label (str): A path to a file which contains class labels.
                       The file should be multiple rows with one column,
                       and string in each row represents a class label.
        model_arch (str): A string to specify model architecture.
                       If ``model_config`` is given, this option will be ignored.
        model_config (str): A path to configure file for building models.
                        If the configure file is not given or does not exist at the specified
                        path, then load the default configure file according ``model_arch``.
        model_weight (str): A path to a model weights. If ``None``, then use the initial
                        value that randomly generated by the packages.
        workspace (str): A path to workspace directory. Log information and checkpoints of model
                     training will be stored in this directory.
                     If ``None``, then create temporary directory in the current directory.
    
    Examples:
        >>> from justdeepit.models import IS
        >>> 
        >>> # initialize Mask RCNN with random weights
        >>> model = IS('./class_label.txt', model_arch='maskrcnn')
        >>> 
        >>> # initialize Mask RCNN with trained weights
        >>> model = IS('./class_label.txt', model_arch='maskrcnn', mdoel_weight='trained_weight.pth')
        >>> 
    """  
    
    
    def __init__(self,
                 class_label=None,
                 model_arch=None,
                 model_config=None,
                 model_weight=None,
                 workspace=None):
        
        self.module = None
        self.__architectures = [['Mask R-CNN', 'mask-rcnn_x101-64x4d_fpn_ms-poly_3x_coco'],
                ['Cascade Mask R-CNN', 'cascade-mask-rcnn_x101-64x4d_fpn_ms-3x_coco'],
                ['custom',    None]]
        self.__supported_formats = ('COCO', 'VoTT')
        self.__image_ext = ['.jpg', '.jpeg', '.png', '.tif', '.tiff']
        
        self.model_arch = model_arch
        if workspace is None:
            workspace = os.path.abspath(os.getcwd())
        self.workspace = workspace
        self.module = self.__init_module(class_label, model_arch, model_config, model_weight, workspace)
    


    
    
    def __init_module(self, class_label, model_arch, model_config, model_weight, workspace):
        if model_arch is None:
            return None
        
        model_arch_ = self.__norm_arch(model_arch)
        
        if model_config is None:
            # check model arch
            if model_arch_ not in [self.__norm_arch(_[0]) for _ in self.__architectures]:
                NotImplementedError('JustDeepIt does not support {} archtecture when {} is specified as a backend.'.format(model_arch, backend))
            # set model_config according to model_arch
            for available_arch, available_config in self.__architectures:
                if model_arch_ == self.__norm_arch(available_arch):
                    if model_arch_ == 'custom':
                        if model_config is None or  model_config == '':
                            ValueError('The argument `model_config` cannot be none or empty when the user customized architecture is set.')
                    else:
                        model_config = available_config
                    break

        # init module
        return MMDetBase(class_label, model_arch, model_config, model_weight, 'is', workspace)



    def __norm_arch(self, arch):
        return arch.replace('-', '').replace(' ', '').lower()




    def available_architectures(self):
        """Display the pre-trained architectures for instance segmentation

        This method is used to display the DNN architectures pre-trained
        in JustDeepIt for instance segmentation.
        As the different backend supports the
        different architectures, this method requires user to specify
        the backend.

        Returns:
            A tuple of the supported architecture.

        Examples:
            >>> from justdeepit.models import IS
            >>>
            >>> model = IS()
            >>> model.available_architectures('mmdetection')

        """
        return tuple([_[0] for _ in self.__architectures])


    

    def supported_formats(self):
        """Display the supported annotation formats for training
        
        Display the supported annotation formats for traning instance segmentation architecture.

        Returns:
            A tuple of the supported annotation formats.

        Examples:
            >>> from justdeepit.models import IS
            >>>
            >>> model = IS()
            >>> model.supported_formats()

        """
        return self.__supported_formats



    def __norm_format(self, x):
        x = x.replace(' ', '').replace('-', '').lower()
        if ('pascal' in x) or ('xml' in x):
            x = 'voc'
        return x
    

    
    def train(self, train_datast, valid_dataset=None, test_dataset=None,
              annotation_format='COCO',
              optimizer=None, scheduler=None,
              score_cutoff=0.5,
              batchsize=8, epoch=100, cpu=4, gpu=1):
        """Train model
 
        The :func:`train <justdeepit.models.IS.train>` is used for training a model.
        
        Args:
            train_dataset (dict): A dictionary contains information of training dataset.
                                  This dictioanry contains three keys, `images` represents
                                  a path to directory which contains all training images,
                                  `annotations` represents a path to a file
                                  (COCO format), and
                                  `format` represents an annotation format (`'coco'`).
            valid_dataset (dict): A dictionary contains information of validation dataset.
            test_dataset (dict): A dictionary contains information of test dataset.
            optimizer (str): String to specify optimizer supported by MMDetection.
            scheduler (str): String to specify optimization scheduler.
            score_cutoff (float): Cutoff of score for object detection.
            batchsize (int): Batch size for each GPU.
            epoch (int): Epoch.
            cpu (int): Number of workers for pre-prociessing images for each GPU.
            gpu (int): Number of GPUs for model training.
        
        Examples:
            >>> from justdeepit.models import IS 
            >>> 
            >>> model = IS('./class_label.txt', model_arch='maskrcnn')
            >>> 
            >>> train_dataset = {'images': './train_images',
            >>>                  'annotations': './train_annotations.json',
            >>>                  'annotation_format': 'coco'}
            >>>
            >>> model.train(train_dataset)
            >>> 
        """
        train_dataset = self.__convert_dataset(train_datast)
        valid_dataset = self.__convert_dataset(valid_dataset)
        test_dataset = self.__convert_dataset(test_dataset)

        self.module.train(train_datast, valid_dataset, test_dataset,
                          optimizer, scheduler, score_cutoff,
                          batchsize, epoch,
                          cpu=cpu, gpu=gpu)
    
    

    def __convert_dataset(self, data_dict):
        if data_dict is None:
            return None
        
        data_fmt = self.__norm_format(data_dict['annotation_format'])

        if data_fmt == 'coco':
            pass
        elif data_fmt == 'voc':
            anns = ImageAnnotations()
            for fpath in glob.glob(os.path.join(data_dict['images'], '*')):
                fname, fext = os.path.splitext(os.path.basename(fpath))
                if fext.lower() in self.__image_ext:
                    ann_fpath = os.path.join(data_dict['annotations'], fname + '.xml')
                    if os.path.exists(ann_fpath):
                        anns.append(ImageAnnotation(fpath, ann_fpath))
            if len(anns) > 0:
                data_dict['annotations'] = os.path.join(self.workspace, 'train_image_annotation.coco.json')
                anns.format('coco', data_dict['annotations'])
        elif data_fmt == 'vott':
            anns = ImageAnnotations()
            for fpath in glob.glob(os.path.join(data_dict['images'], '*')):
                fname, fext = os.path.splitext(os.path.basename(fpath))
                if fext.lower() in self.__image_ext:
                    anns.append(ImageAnnotation(fpath, data_dict['annotations']))
            if len(anns) > 0:
                data_dict['annotations'] = os.path.join(self.workspace, 'train_image_annotation.coco.json')
                anns.format('coco', data_dict['annotations'])
        else:
            raise NotImplementedError('JustDeepIt does not support {} format for training object detection model.'.format(data_fmt))

        return data_dict
    
    
    
    def save(self, weight_fpath, config_fpath=None):
        '''Save the trained model
        
        Method :func:`save <justdeepit.models.IS.save>`
        stores the trained model weights and model configuration.
        
        Args:
            weight_fpath (str): A path to save the weights.
            config_fpath (str): A path to save the model configure. If ``None``,
                                then save the configure to file with same name
                                of ``weight_fpath`` but different extension.
        
        Examples:
            >>> from justdeepit.models import IS
            >>> 
            >>> model = IS('./class_label.txt', model_arch='maskrcnn')
            >>> model.train('./train_images', './annotations.coco.json')
            >>> odnet.save('./trained_weight.pth')
        ''' 
        self.module.save(weight_fpath, config_fpath)
    
    
    
    def inference(self, images, score_cutoff=0.5, batchsize=8, cpu=4, gpu=1):
        '''Detect objects from images
        
        Method :func:`inference <justdeepit.models.IS.inference>` is used to
        detect objects from an image or images with a given model (weights).
        
        Args:
            images (str): A path to a image file or a path to a directory which contains
                          multiple images.
            score_cutoff (float): Cutoff for instance segmentation.
            batchsize (int): Number of batches.
            cpu (int): Number of CPUs.
            gpu (int): Number of GPUs.
        
        Returns:
            :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object
            or a list of :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object.
        
        Examples:
            >>> import os
            >>> from justdeepit.models import IS 
            >>> 
            >>> model = IS('./class_label.txt', model_arch='maskrcnn', model_weight='./trained_weight.pth')
            >>> 
            >>> # inference single image
            >>> output = model.inference('sample.jpg')
            >>> output.draw('contour', 'output/sample.png')
            >>> 
            >>> # inference multiple images
            >>> test_images = ['sample1.jpg', 'sample2.jpg', 'sample3.jpg']
            >>> outputs = model.inference(sample_images)
            >>> for test_image, output in zip(test_images, outputs):
            >>>     bbox_img_fpath = os.path.splitext(test_image)[0] + '.bbox.png'
            >>>     output.draw('bbox+contour', bbox_img_fpath)
            >>> 
        '''
        
        return self.module.inference(images, score_cutoff=score_cutoff, batchsize=batchsize, cpu=cpu, gpu=gpu)
 