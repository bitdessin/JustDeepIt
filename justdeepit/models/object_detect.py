import os
import glob
import pkg_resources
from justdeepit.utils import ImageAnnotation, ImageAnnotations


class OD:
    """A class to generate model for object detection
    
    The :class:`OD <justdeepit.models.OD>` class is used for generating
    deep neural network (DNN) architectures (i.e., models) for object detection
    by internally calling the MMDetection or Detectron2 library.
    
    User can specify DNN architectures using the ``model_arch`` or ``model_config``
    argument. If the ``model_arch`` is specified and ``model_config`` is ``None``,
    the :class:`OD <justdeepit.models.OD>` class generates a DNN architecture
    according the ``model_arch`` using the pre-defined configuration.
    The pre-defined DNN architectures for object detection can be checked with the
    :func:`available_architectures <justdeepit.models.OD.available_architectures>` method.
    Alternatively, if the ``model_config`` argument is specified,
    the :class:`OD <justdeepit.models.OD>` class generates a DNN architecture
    following the configuration specified with the ``model_config``,
    regardless of whether the ``model_arch`` is specified.
    
    The backend for generating DNN architectures can be specified to the MMDetection
    or Detectron2. Currently, the MMDetection supports more architectures than Detectron2
    and model training under GPU environments. Detectron2 can train architectures
    fast and supports CPU and GPU environments.


    Args:
        class_label (str): A path to a file which contains class labels.
                       The file should be multiple rows with one column,
                       and string in each row represents a class label.
        model_arch (str): A string to specify model architecture.
                       If ``model_config`` is given, this option will be ignored.
        model_config (str): A path to configure file for building models.
                        If the configure file is not given or does not exist at the specified
                        path, then load the default configure file according ``model_arch``.
        model_weight (str): A path to a model weights. If ``None``, then use the initial
                        value that randomly generated by the packages.
        workspace (str): A path to workspace directory. Log information and checkpoints of model
                     training will be stored in this directory.
                     If ``None``, then create temporary directory in the current directory.
        backend (str): Specify the backend to build object detection mode.
                   ``detectron2`` or ``mmdetection`` can be speficied.
    
    Examples:
        >>> from justdeepit.models import OD
        >>> 
        >>> # initialize Faster RCNN with random weights using MMDetection backend
        >>> model = OD('./class_label.txt', model_arch='fasterrcnn', backend='mmdetection')
        >>> 
        >>> # initialize Faster RCNN with randomm weights using Detectron2 backend
        >>> model = OD('./class_label.txt', model_arch='fasterrcnn', backend='detectron2')
        >>> 
        >>> # initialize RetinaNet with trained weights using MMDetection backend
        >>> model = OD('./class_label.txt', model_arch='retinanet', mdoel_weight='trained_weight.pth',
        >>>            backend='mmdetection')
        >>> 
        >>> # initialize RetinaNet with trained weights using Detectron2 backend
        >>> model = OD('./class_label.txt', model_arch='retinanet', model_weight='trained_weight.pth',
        >>>            backend='detectron2')
        >>> 
    """  
    
    
    
    def __init__(self, class_label=None,
                 model_arch=None, model_config=None, model_weight=None,
                 workspace=None, backend='mmdetection'):
        
        self.module = None
        self.__architectures = self.__available_architectures()
        self.__supported_formats = ('COCO', 'Pascal VOC')
        self.__image_ext = ['.jpg', '.jpeg', '.png', '.tif', '.tiff']
        
        self.backend = backend
        self.model_arch = model_arch
        if workspace is None:
            workspace = os.path.abspath(os.getcwd())
        self.workspace = workspace
        self.module = self.__init_module(class_label, model_arch, model_config, model_weight, workspace, backend)
    

    def __available_architectures(self):
        return {
            'mmdetection': [
                ['Faster R-CNN',  'faster_rcnn_r101_fpn_mstrain_3x_coco'],
                ['Cascade R-CNN', 'cascade_rcnn_x101_64x4d_fpn_20e_coco'],
                ['Dynamic R-CNN', 'dynamic_rcnn_r50_fpn_1x_coco'],
                ['RetinaNet',     'retinanet_r101_fpn_mstrain_640-800_3x_coco'],
                ['YOLOv3',        'yolov3_d53_mstrain-608_273e_coco'],
                ['YOLO-F',        'yolof_r50_c5_8x8_1x_coco'],
                ['SSD',           'ssd512_coco'],
                ['FCOS',          'fcos_r101_caffe_fpn_gn-head_mstrain_640-800_2x_coco'],
                ['custom',       None],
            ],
            'detectron2': [
                ['Faster R-CNN', 'COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml'],
                ['RetinaNet',    'COCO-Detection/retinanet_R_101_FPN_3x.yaml'],
                ['custom',      None]
            ]
        }
        
        
    def __init_module(self, class_label, model_arch, model_config, model_weight, workspace, backend):
        if model_arch is None:
            return None
        
        backend_ = self.__norm_backend(backend)
        model_arch_ = self.__norm_arch(model_arch)
        
        if model_config is None:
            # check model arch
            if model_arch_ not in [self.__norm_arch(_[0]) for _ in self.__architectures[backend_]]:
                NotImplementedError('JustDeepIt does not support {} archtecture when {} is specified as a backend.'.format(model_arch, backend))
            
            # set model_config according to model_arch
            for available_arch, available_config in self.__architectures[backend_]:
                if model_arch_ == self.__norm_arch(available_arch):
                    if model_arch_ == 'custom':
                        if model_config is None or  model_config == '':
                            ValueError('The argument `model_config` cannot be `None` or empty when the user customized architecture is set.')
                    else:
                        model_config = available_config
                    break
        
        # init module
        module = None
        if backend_ == 'mmdetection':
            from justdeepit.models.utils.mmdetbase import MMDetBase
            module = MMDetBase(class_label, model_arch, model_config, model_weight, workspace)
        elif backend_ == 'detectron2':
            from justdeepit.models.utils.detectron2base import DetectronBase
            module = DetectronBase(class_label, model_arch, model_config, model_weight, workspace)
        
        return module
    
    
    
    def __norm_arch(self, arch):
        return arch.replace('-', '').replace(' ', '').lower()
    
    
    def __norm_backend(self, backend):
        backend_ = backend.lower()
        if backend in ['mm', 'mmdet', 'mmdetection']:
            backend_ = 'mmdetection'
        elif backend_ in ['d2', 'detectron', 'detectron2']:
            backend_ = 'detectron2'
        else:
            NotImplementedError('JustDeepIt does not support `{}` as a backend.'.format(backend))
        return backend_
    
    
    
    def available_architectures(self, backend):
        """Display the pre-trained architectures for object detection
        
        This method is used to display the DNN architectures pre-trained
        in JustDeepIt for object detection.
        As the different backend supports the
        different architectures, this method requires user to specify
        the backend.
        
        Args:
            backend (str): Specify the backend.
                           ``detectron2`` or ``mmdetection`` can be speficied.
        
        Returns:
            A tuple of the supported architecture.

        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD()
            >>> model.available_architectures('mmdetection')
        
        """
        return tuple([_[0] for _ in self.__architectures[self.__norm_backend(backend)]])
        
    
    
    def supported_formats(self):
        """Display the supported annotation formats for training
        
        Display the supported annotation formats for traning object detection architecture.
        
        Returns:
            A tuple of the supported annotation formats.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD()
            >>> model.supported_formats()
        
        """
        return self.__supported_formats

    
    def __norm_format(self, x):
        x = x.replace(' ', '').replace('-', '').lower()
        if ('pascal' in x) or ('xml' in x):
            x = 'voc'
        return x
    
    
    def train(self, image_dpath, annotation, annotation_format='COCO',
              optimizer=None, scheduler=None,
              batchsize=8, epoch=100, score_cutoff=0.5, cpu=4, gpu=1):
        """Train model
        
        The :func:`train <justdeepit.models.OD.train>` is used for training a model.
        The training images (``image_dpath``), annotation files (``annotation``),
        and annotation format (``annotation_format``) must be specified.
        
        Args:
            image_dpath (str): A path to directory which contains all training images.
            annotation (str): A path to a file (COCO format) or folder
                    (Pascal VOC format, each file should have an extension :file:`.xml`).
            annotation_format (str): Annotation format. COCO or Pascal VOC are supported.
            optimizer (str): String to specify optimizer supported by MMDetection.
            scheduler (str): String to specify optimization scheduler.
            batchsize (int): Batch size for each GPU.
            epoch (int): Epoch.
            score_cutoff (float): Cutoff of score for object detection.
            cpu (int): Number of workers for pre-prociessing images for each GPU.
            gpu (int): Number of GPUs for model training.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn', backend='mmdetection')
            >>> model.train('./train_images', './annotations.coco.json', 'COCO')
            >>> 
            >>> # set optimizer and scheduler
            >>> model.train('./train_images', './annotations.coco.json', 'COCO',
            >>>             optimizer='dict(type="Adam", lr=0.0003, weight_decay=0.0001)',
            >>>             scheduler='dict(policy="CosineAnnealing", warmup="linear", warmup_iters=1000, warmup_ratio=1.0 / 10, min_lr_ratio=1e-5)')
            >>> 
        """
        annotation_format = self.__norm_format(annotation_format)
        if annotation_format == 'coco':
            pass
        elif annotation_format == 'voc':
            anns = ImageAnnotations()
            for fpath in glob.glob(os.path.join(image_dpath, '*')):
                fname, fext = os.path.splitext(os.path.basename(fpath))
                if fext.lower() in self.__image_ext:
                    ann_fpath = os.path.join(annotation, fname + '.xml')
                    if os.path.exists(ann_fpath):
                        anns.append(ImageAnnotation(fpath, ann_fpath))
            if len(anns) > 0:
                annotation = os.path.join(self.workspace, 'train_image_annotation.coco.json')
                anns.format('coco', annotation)
        else:
            raise NotImplementedError('JustDeepIt does not support {} format for training object detection model.'.format(annotation_format))
        
        self.module.train(image_dpath, annotation,
                          optimizer, scheduler,
                          batchsize, epoch, score_cutoff,
                          cpu=cpu, gpu=gpu)
    
    
    
    def save(self, weight_fpath, config_fpath=None):
        '''Save the trained model
        
        Method :func:`save <justdeepit.models.OD.save>`
        stores the trained model weights and model configuration.
        
        Args:
            weight_fpath (str): A path to save the weights.
            config_fpath (str): A path to save the model configure. If ``None``,
                                then save the configure to file with same name
                                of ``weight_fpath`` but different extension.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn')
            >>> model.train('./train_images', './annotations.coco.json')
            >>> odnet.save('./trained_weight.pth')
        ''' 
        self.module.save(weight_fpath, config_fpath)
    
    
    
    def inference(self, images, score_cutoff=0.5, batchsize=8, cpu=4, gpu=1):
        '''Detect objects from images
        
        Method :func:`inference <justdeepit.models.OD.inference>` is used to
        detect objects from an image or images with a given model (weights).
        
        Args:
            images (str): A path to a image file or a path to a directory which contains
                          multiple images.
            score_cutoff (float): Cutoff for object detection.
            batchsize (int): Number of batches.
            cpu (int): Number of CPUs.
            gpu (int): Number of GPUs.
        
        Returns:
            :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object
            or a list of :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object.
        
        Examples:
            >>> import os
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn', model_weight='./trained_weight.pth')
            >>> 
            >>> # inference single image
            >>> output = model.inference('sample.jpg')
            >>> output.draw('contour', 'output/sample.png')
            >>> 
            >>> # inference multiple images
            >>> test_images = ['sample1.jpg', 'sample2.jpg', 'sample3.jpg']
            >>> outputs = model.inference(sample_images)
            >>> for test_image, output in zip(test_images, outputs):
            >>>     bbox_img_fpath = os.path.splitext(test_image)[0] + '.bbox.png'
            >>>     output.draw('bbox', bbox_img_fpath)
            >>> 
        '''
        
        return self.module.inference(images, score_cutoff, batchsize, cpu, gpu)
    
    





