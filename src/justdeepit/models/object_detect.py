import os
import glob
import pkg_resources
from justdeepit.utils import ImageAnnotation, ImageAnnotations
from justdeepit.models.utils.mmdetbase import MMDetBase


class OD:
    """A class to generate model for object detection
    
    The :class:`OD <justdeepit.models.OD>` class is used for generating
    deep neural network (DNN) architectures (i.e., models) for object detection
    by internally calling the MMDetection library.
    
    User can specify DNN architectures using the ``model_arch`` or ``model_config``
    argument. If the ``model_arch`` is specified and ``model_config`` is ``None``,
    the :class:`OD <justdeepit.models.OD>` class generates a DNN architecture
    according the ``model_arch`` using the pre-defined configuration.
    The pre-defined DNN architectures for object detection can be checked with the
    :func:`available_architectures <justdeepit.models.OD.available_architectures>` method.
    Alternatively, if the ``model_config`` argument is specified,
    the :class:`OD <justdeepit.models.OD>` class generates a DNN architecture
    following the configuration specified with the ``model_config``,
    regardless of whether the ``model_arch`` is specified.


    Args:
        class_label (str): A path to a file which contains class labels.
                       The file should be multiple rows with one column,
                       and string in each row represents a class label.
        model_arch (str): A string to specify model architecture.
                       If ``model_config`` is given, this option will be ignored.
        model_config (str): A path to configure file for building models.
                        If the configure file is not given or does not exist at the specified
                        path, then load the default configure file according ``model_arch``.
        model_weight (str): A path to a model weights. If ``None``, then use the initial
                        value that randomly generated by the packages.
        workspace (str): A path to workspace directory. Log information and checkpoints of model
                     training will be stored in this directory.
                     If ``None``, then create temporary directory in the current directory.
    
    Examples:
        >>> from justdeepit.models import OD
        >>> 
        >>> # initialize Faster RCNN with random weights
        >>> model = OD('./class_label.txt', model_arch='fasterrcnn')
        >>> 
        >>> # initialize RetinaNet with trained weights
        >>> model = OD('./class_label.txt', model_arch='retinanet', mdoel_weight='trained_weight.pth')
        >>> 
    """  
    
    
    
    def __init__(self,
                 class_label=None,
                 model_arch=None,
                 model_config=None,
                 model_weight=None,
                 workspace=None):
        
        self.module = None
        self.__architectures = [['Faster R-CNN', 'faster-rcnn_r101_fpn_ms-3x_coco'],
                ['RetinaNet', 'retinanet_r101_fpn_ms-640-800-3x_coco'],
                ['YOLOv3', 'yolov3_d53_mstrain-608_273e_coco'],
                ['YOLO-F', 'yolof_r50_c5_8x8_1x_coco'],
                ['SSD', 'ssd512_coco'],
                ['FCOS', 'fcos_r101-caffe_fpn_gn-head_ms-640-800-2x_coco'],
                ['custom', None]]
        self.__supported_formats = ('COCO', 'Pascal VOC', 'VoTT')
        self.__image_ext = ['.jpg', '.jpeg', '.png', '.tif', '.tiff']

        self.model_arch = model_arch
        if workspace is None:
            workspace = os.path.abspath(os.getcwd())
        self.workspace = workspace
        self.module = self.__init_module(class_label, model_arch, model_config, model_weight, workspace)
    

        
        
    def __init_module(self, class_label, model_arch, model_config, model_weight, workspace):
        if model_arch is None:
            return None
        
        model_arch_ = self.__norm_arch(model_arch)
        
        if model_config is None:
            # check model arch
            if model_arch_ not in [self.__norm_arch(_[0]) for _ in self.__architectures]:
                NotImplementedError('JustDeepIt does not support {} archtecture.'.format(model_arch))
            # set model_config according to model_arch
            for available_arch, available_config in self.__architectures:
                if model_arch_ == self.__norm_arch(available_arch):
                    if model_arch_ == 'custom':
                        if model_config is None or model_config == '':
                            ValueError('The argument `model_config` cannot be `None` or empty when the user customized architecture is set.')
                    else:
                        model_config = available_config
                    break
        
        # init module
        return MMDetBase(class_label, model_arch, model_config, model_weight, 'od', workspace)
    
    
    
    def __norm_arch(self, arch):
        return arch.replace('-', '').replace(' ', '').lower()    
    
    
    def available_architectures(self):
        """Display the pre-trained architectures for object detection
        
        This method is used to display the DNN architectures pre-trained
        in JustDeepIt for object detection.
        
        Returns:
            A tuple of the supported architecture.

        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD()
            >>> model.available_architectures()
        
        """
        return tuple([_[0] for _ in self.__architectures])
        
    
    
    def supported_formats(self):
        """Display the supported annotation formats for training
        
        Display the supported annotation formats for traning object detection architecture.
        
        Returns:
            A tuple of the supported annotation formats.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD()
            >>> model.supported_formats()
        
        """
        return self.__supported_formats

    
    def __norm_format(self, x):
        x = x.replace(' ', '').replace('-', '').lower()
        if ('pascal' in x) or ('xml' in x):
            x = 'voc'
        return x
    
    
    def train(self,
              train_datast,
              valid_dataset=None,
              test_dataset=None,
              optimizer=None,
              scheduler=None,
              score_cutoff=0.5,
              batchsize=8,
              epoch=100,
              cpu=4,
              gpu=1):
        """Train model
        
        The :func:`train <justdeepit.models.OD.train>` is used for training a model.
        
        Args:
            train_dataset (dict): A dictionary contains information of training dataset.
                                  This dictioanry contains three keys, `images` represents
                                  a path to directory which contains all training images,
                                  `annotations` represents a path to a file
                                  (COCO, VoTT format) or folder (Pascal VOC format,
                                  each file should have an extension :file:`.xml`), and
                                  `format` represents an annotation format.
            valid_dataset (dict): A dictionary contains information of validation dataset.
            test_dataset (dict): A dictionary contains information of test dataset.
            optimizer (str): String to specify optimizer supported by MMDetection.
            scheduler (str): String to specify optimization scheduler.
            score_cutoff (float): Cutoff of score for object detection.
            batchsize (int): Batch size for each GPU.
            epoch (int): Epoch.
            cpu (int): Number of workers for pre-prociessing images for each GPU.
            gpu (int): Number of GPUs for model training.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn')
            >>>
            >>> train_dataset = {'images': './train_images',
            >>>                  'annotations': './train_annotations.json',
            >>>                  'annotation_format': 'coco'}
            >>>
            >>> model.train(train_dataset)
            >>> 
            >>> # set optimizer and scheduler
            >>> model.train(train_dataset,
            >>>             optimizer='dict(type="Adam", lr=0.0003, weight_decay=0.0001)',
            >>>             scheduler='dict(policy="CosineAnnealing", warmup="linear", warmup_iters=1000, warmup_ratio=1.0 / 10, min_lr_ratio=1e-5)')
            >>> 
        """
        train_dataset = self.__convert_dataset(train_datast)
        valid_dataset = self.__convert_dataset(valid_dataset)
        test_dataset = self.__convert_dataset(test_dataset)

        self.module.train(train_datast, valid_dataset, test_dataset,
                          optimizer, scheduler, score_cutoff,
                          batchsize, epoch,
                          cpu=cpu, gpu=gpu)
    
    
    def __convert_dataset(self, data_dict):
        if data_dict is None:
            return None
        
        data_fmt = self.__norm_format(data_dict['annotation_format'])

        if data_fmt == 'coco':
            pass
        elif data_fmt == 'voc':
            anns = ImageAnnotations()
            for fpath in glob.glob(os.path.join(data_dict['images'], '*')):
                fname, fext = os.path.splitext(os.path.basename(fpath))
                if fext.lower() in self.__image_ext:
                    ann_fpath = os.path.join(data_dict['annotations'], fname + '.xml')
                    if os.path.exists(ann_fpath):
                        anns.append(ImageAnnotation(fpath, ann_fpath))
            if len(anns) > 0:
                data_dict['annotations'] = os.path.join(self.workspace, 'train_image_annotation.coco.json')
                anns.format('coco', data_dict['annotations'])
        elif data_fmt == 'vott':
            anns = ImageAnnotations()
            for fpath in glob.glob(os.path.join(data_dict['images'], '*')):
                fname, fext = os.path.splitext(os.path.basename(fpath))
                if fext.lower() in self.__image_ext:
                    anns.append(ImageAnnotation(fpath, data_dict['annotations']))
            if len(anns) > 0:
                data_dict['annotations'] = os.path.join(self.workspace, 'train_image_annotation.coco.json')
                anns.format('coco', data_dict['annotations'])
        else:
            raise NotImplementedError('JustDeepIt does not support {} format for training object detection model.'.format(data_fmt))

        return data_dict


    
    def save(self, weight_fpath, config_fpath=None):
        '''Save the trained model
        
        Method :func:`save <justdeepit.models.OD.save>`
        stores the trained model weights and model configuration.
        
        Args:
            weight_fpath (str): A path to save the weights.
            config_fpath (str): A path to save the model configure. If ``None``,
                                then save the configure to file with same name
                                of ``weight_fpath`` but different extension.
        
        Examples:
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn')
            >>> model.train('./train_images', './annotations.coco.json')
            >>> odnet.save('./trained_weight.pth')
        ''' 
        self.module.save(weight_fpath, config_fpath)
    
    
    
    def inference(self, images, score_cutoff=0.5, batchsize=8, cpu=4, gpu=1):
        '''Detect objects from images
        
        Method :func:`inference <justdeepit.models.OD.inference>` is used to
        detect objects from an image or images with a given model (weights).
        
        Args:
            images (str): A path to a image file or a path to a directory which contains
                          multiple images.
            score_cutoff (float): Cutoff for object detection.
            batchsize (int): Number of batches.
            cpu (int): Number of CPUs.
            gpu (int): Number of GPUs.
        
        Returns:
            :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object
            or a list of :class:`ImageAnnotation <justdeepit.utils.ImageAnnotation>` class object.
        
        Examples:
            >>> import os
            >>> from justdeepit.models import OD
            >>> 
            >>> model = OD('./class_label.txt', model_arch='fasterrcnn', model_weight='./trained_weight.pth')
            >>> 
            >>> # inference single image
            >>> output = model.inference('sample.jpg')
            >>> output.draw('contour', 'output/sample.png')
            >>> 
            >>> # inference multiple images
            >>> test_images = ['sample1.jpg', 'sample2.jpg', 'sample3.jpg']
            >>> outputs = model.inference(sample_images)
            >>> for test_image, output in zip(test_images, outputs):
            >>>     bbox_img_fpath = os.path.splitext(test_image)[0] + '.bbox.png'
            >>>     output.draw('bbox', bbox_img_fpath)
            >>> 
        '''
        
        return self.module.inference(images, score_cutoff, batchsize, cpu, gpu)
